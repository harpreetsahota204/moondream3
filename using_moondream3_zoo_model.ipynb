{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/moondream3/blob/main/using_moondream3_zoo_model.ipynb)\n",
    "\n",
    "If opening in Colab, be sure to install:\n",
    "\n",
    "`pip install fiftyone`\n",
    "\n",
    "# Using Moondream3 as Remotely Sourced Zoo Model\n",
    "\n",
    "\n",
    "<div style=\"background-color: #fff3cd; border: 1px solid #856404; border-radius: 5px; padding: 15px; margin: 10px 0; color: #856404;\">\n",
    "<strong>⚠️ NOTE:</strong> This is a gated model. You need to request access to it and then log into Hugging Face with your token by running hf auth login in your terminal and passing your token.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "\n",
    "dataset = fouh.load_from_hub(\n",
    "    \"Voxel51/GQA-Scene-Graph\",\n",
    "    max_samples=50,\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "sample_objects = dataset.values(\"detections.detections.label\")\n",
    "\n",
    "sample_level_objects =  [list(set(obj)) for obj in sample_objects]\n",
    "\n",
    "dataset.set_values(\"sample_level_objects\", sample_level_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first image for context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(dataset.first().filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "foz.register_zoo_model_source(\"https://github.com/harpreetsahota204/moondream3\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "foz.download_zoo_model(\n",
    "    \"https://github.com/harpreetsahota204/moondream3\",\n",
    "    model_name=\"moondream/moondream3-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Moondream2 has frequent updates, you can check the versions [here](https://huggingface.co/vikhyatk/moondream2/blob/main/versions.txt) and pass the most recent one or any previous versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "model = foz.load_zoo_model(\n",
    "    \"moondream/moondream3-preview\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream3 for Zero Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"classify\"\n",
    "model.prompt= \"Pick one of the animals the image: horse, giraffe, elephant, shark\"\n",
    "\n",
    "dataset.apply_model(\n",
    "    model, \n",
    "    label_field=\"classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream3 for Captions\n",
    "\n",
    "The three captioning operations require no additional arguments beyond selecting the operation type. \n",
    "\n",
    "Supported `length` values:\n",
    "\n",
    "* `short`\n",
    "\n",
    "* `normal`\n",
    "\n",
    "* `long`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"caption\"\n",
    "model.length= \"short\"\n",
    "\n",
    "dataset.apply_model(\n",
    "    model, \n",
    "    label_field=\"short_captions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['short_captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.length= \"long\"\n",
    "\n",
    "dataset.apply_model(\n",
    "    model, \n",
    "    label_field=\"long_captions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['long_captions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream3 for Detection\n",
    "\n",
    "\n",
    "The results are stored as Detections objects containing bounding boxes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"detect\"\n",
    "\n",
    "dataset.apply_model(model, prompt_field=\"sample_level_objects\", label_field=\"detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['detections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also supports passing a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prompt=[\"horse\", \"house\", \"saddle\", \"man\", \"black jacket\"]\n",
    "\n",
    "dataset.apply_model(model,label_field=\"list_detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['list_detections']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream3 for Keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"point\"\n",
    "\n",
    "dataset.apply_model(model, prompt_field=\"sample_level_objects\", label_field=\"pointings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['pointings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also supports lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prompt=[\"horse\", \"house\", \"saddle\", \"man\", \"black jacket\"]\n",
    "\n",
    "dataset.apply_model(model,label_field=\"list_points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()[\"list_points\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Moondream3 for VQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"query\"\n",
    "\n",
    "model.prompt=\"What is the in the background of the image\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"vqa_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['vqa_response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to use a Field of a Sample for grounding, you use the following pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_values(\"questions\", [\"Where is the general location of this scene?\"]*len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(\n",
    "    model,\n",
    "    label_field=\"query_field_response\",\n",
    "    prompt_field=\"questions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['query_field_response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Grounding\n",
    "\n",
    "This model doesn't support phrase grounding out of the box, but a hacky way you can do this is by passing the caption as a `prompt_field`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"detect\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"grounded_detections\", prompt_field=\"short_captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['grounded_detections']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
